# ğŸ“˜ Î˜ (Theta) Notation â€” Tight Bound Complexity

## 1ï¸âƒ£ What is Î˜ (Theta)?

**Î˜ (Theta) notation** describes the **exact (tight) bound** of an algorithmâ€™s time complexity.

In simple terms:

> Î˜ tells you that an algorithmâ€™s runtime grows **at the same rate** in both the best and worst cases (up to constants).

If:

* **Big-O** = upper bound (worst case)
* **Omega (Î©)** = lower bound (best guaranteed case)

Then:

> **Theta (Î˜)** = upper **and** lower bound together.

---

## â“ Why Is Î˜ Important?

Î˜ answers the most practical question:

> *How does this algorithm really scale?*

It gives:

* Precise growth rate
* Predictable performance
* Clear comparison between algorithms

If an algorithm is Î˜(n), you **know exactly** how it behaves asymptotically.

---

## ğŸ“Œ Formal Definition

An algorithm is **Î˜(f(n))** if:

```
There exist constants câ‚, câ‚‚ > 0 and nâ‚€ such that
câ‚ Â· f(n) â‰¤ T(n) â‰¤ câ‚‚ Â· f(n) for all n â‰¥ nâ‚€
```

Meaning:

* Runtime is **sandwiched** between two constant multiples of `f(n)`
* Growth rate is tightly bounded

---

## ğŸ’» Code Examples

### 1ï¸âƒ£ Î˜(1) â€” Constant Time

```python
def get_last_element(arr):
    return arr[-1]
```

* Best case = Worst case = Î˜(1)

---

### 2ï¸âƒ£ Î˜(n) â€” Linear Time

```python
def sum_array(arr):
    total = 0
    for x in arr:
        total += x
    return total
```

* Must traverse all elements
* Best case = Worst case = Î˜(n)

---

### 3ï¸âƒ£ Î˜(n log n) â€” Divide & Conquer

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)
```

* Same asymptotic behavior regardless of input
* Î˜(n log n)

---

## ğŸš€ Real-World NLP Example

### Vocabulary Building

When building a vocabulary from a corpus of `n` tokens:

* You must read every token
* Hash-table insert/lookups are Î˜(1) on average

â¡ï¸ Total complexity = **Î˜(n)**

This is both the best and worst asymptotic case.

---

## ğŸ§  Relationship Between O, Î©, and Î˜

| Scenario            | Result           |
| ------------------- | ---------------- |
| O(f(n)) and Î©(f(n)) | Î˜(f(n))          |
| Only O known        | Upper bound only |
| Only Î© known        | Lower bound only |

Example:

```
O(n) and Î©(n)  â‡’  Î˜(n)
```

---

## ğŸ“Š Comparison Table

| Algorithm     | O          | Î©          | Î˜          |
| ------------- | ---------- | ---------- | ---------- |
| Array Access  | O(1)       | Î©(1)       | Î˜(1)       |
| Find Max      | O(n)       | Î©(n)       | Î˜(n)       |
| Linear Search | O(n)       | Î©(1)       | Î˜(?)       |
| Merge Sort    | O(n log n) | Î©(n log n) | Î˜(n log n) |

âš ï¸ Note:
Linear Search has **no Î˜ bound** because best and worst cases differ.

---

âœ… **Key Insight:**
Î˜ is the **most informative notation**.

When you can prove Î˜(f(n)), you fully understand the algorithmâ€™s scalability.

This is the level expected when:

* Designing systems
* Writing production algorithms
* Answering senior-level interviews ğŸ’ª
